{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnIDqqye2wiY"
      },
      "source": [
        "# One-Pixel Attacks\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Review of J. Su et al. paper on one pixel attacks for fooling deep neural networks\n",
        "\n",
        "Paper: https://arxiv.org/abs/1710.08864\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Aims & Objectives:**\n",
        "\n",
        "\n",
        "1.   Reproduce the code and findings found from this paper\n",
        "2.   Build a differential evolution model to manipulate some of the best deep neural networks\n",
        "3.   Use one pixel pertubations to fool networks such as VGG on the CIFAR-10 and ImageNet datasets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWvWSYP63HXR"
      },
      "source": [
        "# Imports and Upload Image Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyrOdfXH8WU7",
        "outputId": "ce13c802-02e2-4790-b070-94ba11d9b31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py7zr\n",
            "  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Collecting texttable (from py7zr)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from py7zr) (3.23.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from py7zr) (1.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from py7zr) (5.9.5)\n",
            "Collecting pyzstd>=0.16.1 (from py7zr)\n",
            "  Downloading pyzstd-0.18.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting pyppmd<1.3.0,>=1.1.0 (from py7zr)\n",
            "  Downloading pyppmd-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading inflate64-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.13.2 in /usr/local/lib/python3.12/dist-packages (from pyzstd>=0.16.1->py7zr) (4.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.18.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (429 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m429.9/429.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed inflate64-1.0.3 multivolumefile-0.2.3 py7zr-1.0.0 pybcj-1.0.6 pyppmd-1.2.0 pyzstd-0.18.0 texttable-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install py7zr gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rUCLFEki2rL1"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "from google.colab import drive\n",
        "import os\n",
        "import py7zr\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from numpy import asarray\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "import random\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scipy.optimize import differential_evolution\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downlaod and Process Input Data"
      ],
      "metadata": {
        "id": "cBIkVFYEVgwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OM_tkn_35DYA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def download(file_id, file_name, unzip=False):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, file_name, quiet=False)\n",
        "    if unzip:\n",
        "        extract_dir = os.path.splitext(file_name)[0]\n",
        "        os.makedirs(extract_dir, exist_ok=True)\n",
        "        with py7zr.SevenZipFile(file_name, mode='r') as archive:\n",
        "            archive.extractall(path=extract_dir)\n",
        "        print(f\"✅ Extracted '{file_name}' into folder '{extract_dir}/'\")\n",
        "def downloadData():\n",
        "  # the IDs of the files stored on google drive\n",
        "  labels = \"1DieuXWsbM4x_hVUOAY7Z2GhcR1Mk0dgN\"\n",
        "  train = \"1wOChHhwX6ANgLv2YCJpiYEtkPvFchy4G\"\n",
        "  #test = \"12qMQYpS_4bKqroVUE-J5GCDRk41s2Tv5\"\n",
        "  download(labels, \"trainLabels.csv\")\n",
        "  download(train, \"train.7z\", unzip=True)\n",
        "\n",
        "\n",
        "def convertYVals(yvals, noOutputs=10):\n",
        "   out = []\n",
        "   for val in yvals:\n",
        "      #arr = np.zeros(1)\n",
        "      #arr[0] = val\n",
        "      out.append(val)\n",
        "      #out.append(np.array(val))\n",
        "   out = np.array(out)\n",
        "   return out\n",
        "\n",
        "\n",
        "def splitData(ratio, train_data, train_labels, num_test_images, seed=42):\n",
        "  yVals = convertYVals(train_labels)\n",
        "  random.seed(42)\n",
        "\n",
        "  temp = list(zip(train_data, train_labels))\n",
        "  random.shuffle(temp)\n",
        "  res1, res2 = zip(*temp)\n",
        "  train_data, train_labels = list(res1), list(res2)\n",
        "\n",
        "  split_index = int((ratio * len(train_data)) // 1)\n",
        "  x_val, y_val = np.array(train_data[:split_index]), np.array(train_labels[:split_index])\n",
        "  x_train, y_train = np.array(train_data[split_index:]), np.array(train_labels[split_index:])\n",
        "\n",
        "  n = len(x_val) - num_test_images\n",
        "  x_test, y_test = x_val[n:], y_val[n:]\n",
        "  x_val, y_val = x_val[:n], y_val[:n]\n",
        "\n",
        "\n",
        "  return (x_train,x_val,x_test,y_train,y_val,y_test)\n",
        "\n",
        "\n",
        "\n",
        "def organiseData():\n",
        "    downloadData()\n",
        "    noImgs = len([name for name in os.listdir('train/train')])\n",
        "    train_labels = np.zeros(noImgs)\n",
        "    inv_keys = {\"dog\":0,\"frog\":1,\"truck\":2,\"deer\":3 , \"automobile\":4, \"bird\":5, \"horse\":6,\"ship\":7,\"cat\":8,\"airplane\":9}\n",
        "\n",
        "\n",
        "    with open(\"trainLabels.csv\", \"r\") as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            image_id = line.split(\",\")[0]\n",
        "            image_label = line.split(\",\")[1]\n",
        "            train_labels[(int)(image_id)-1] = inv_keys[image_label.strip()]\n",
        "\n",
        "    train_images=[]\n",
        "    for i in range(noImgs):\n",
        "        path = \"train/train/\"+ str(i+1) + \".png\" #png 1 indexed in folder so add 1 to i\n",
        "        img = PIL.Image.open(path) # Load image\n",
        "        a= np.asarray(img)\n",
        "        train_images.append(a)\n",
        "\n",
        "\n",
        "    ratio = 0.2\n",
        "    num_test_images = 500\n",
        "    train_images = np.array(train_images)\n",
        "    (x_train,x_val,x_test,y_train,y_val,y_test) = splitData(ratio, train_images , train_labels, num_test_images, seed=42)\n",
        "    y_train, y_val, y_test = y_train.flatten(), y_val.flatten(), y_test.flatten()\n",
        "\n",
        "    return {\"x_train\":x_train, \"x_val\":x_val,\"x_test\":x_test,\"y_train\":y_train,\"y_val\":y_val,\"y_test\":y_test}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTdGfn7mJ0gY"
      },
      "source": [
        "#Load Models for Differential Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "teJle2Tr9Utu"
      },
      "outputs": [],
      "source": [
        "\n",
        "label_keys = {0:\"dog\",1:\"frog\", 2:\"truck\", 3:\"deer\", 4:\"automobile\", 5:\"bird\", 6:\"horse\", 7:\"ship\", 8:\"cat\",9:\"airplane\" }\n",
        "inv_keys = {\"dog\":0,\"frog\":1,\"truck\":2,\"deer\":3 , \"automobile\":4, \"bird\":5, \"horse\":6,\"ship\":7,\"cat\":8,\"airplane\":9}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all convolutional network\n",
        "def createAllConvNetwork():\n",
        "  model = keras.Sequential([\n",
        "    layers.Conv2D(96, (3,3), activation='relu',padding='same',  input_shape=(32,32,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(96, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(96, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(192, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(192, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(192, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(192, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(192, (1,1), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(10, (1,1), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.AveragePooling2D(pool_size=(6, 6)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def createNetworkInNetwork():\n",
        "  model = keras.Sequential([\n",
        "    layers.Conv2D(192, (5,5), activation='relu',padding='same', input_shape=(32,32,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(160, (1,1), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(96, (1,1), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.AveragePooling2D(pool_size=(3, 3), strides=(2,2),padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Conv2D(192, (5,5), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(192, (5,5), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(192, (5,5), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.AveragePooling2D(pool_size=(3, 3), strides=(2,2),padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Conv2D(192, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(192, (1,1), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(10, (1,1), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.AveragePooling2D(pool_size=(8, 8),padding='same'),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "#vgg network\n",
        "def createVGG():\n",
        "  model = keras.Sequential([\n",
        "    layers.Conv2D(64, (3,3), activation='relu',padding='same',  input_shape=(32,32,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'),\n",
        "\n",
        "    layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'),\n",
        "\n",
        "    layers.Conv2D(512, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(512, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(512, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'),\n",
        "\n",
        "    layers.Conv2D(512, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(512, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(512, (3,3), activation='relu',padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(2048, activation='relu'),\n",
        "    layers.Dense(2048, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Lom4WAYIXVeP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trainModels(models,data):\n",
        "    EPOCHS=100\n",
        "    BATCHSIZE=64\n",
        "    print(models)\n",
        "    history = models[\"nin\"].fit(\n",
        "        data[\"x_train\"],\n",
        "        data[\"y_train\"],\n",
        "        batch_size=BATCHSIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(data[\"x_test\"], data[\"y_test\"]),\n",
        "        callbacks=[EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001, restore_best_weights=True)]\n",
        "    )\n",
        "    history = models[\"vgg\"].fit(\n",
        "        data[\"x_train\"],\n",
        "        data[\"y_train\"],\n",
        "        batch_size=BATCHSIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(data[\"x_test\"], data[\"y_test\"]),\n",
        "        callbacks=[EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001, restore_best_weights=True)]\n",
        "    )\n",
        "    history = models[\"conv\"].fit(\n",
        "        data[\"x_train\"],\n",
        "        data[\"y_train\"],\n",
        "        batch_size=BATCHSIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(data[\"x_test\"], data[\"y_test\"]),\n",
        "        callbacks=[EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001, restore_best_weights=True)]\n",
        "    )\n",
        "    return models\n"
      ],
      "metadata": {
        "id": "7T1yHMbwXim1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createModels(data , train=False):\n",
        "    if not train:\n",
        "      allconv = \"1AzSxkN6oYEbwlGEyLNSFGHsMKZRkBqzh\"\n",
        "      nin = \"1OreWkCmQFr62Ekk6wvXtSeqXIy5154es\"\n",
        "      vgg = \"1x0clBBspx8DAQ3b1KbSROYKgaCqvO_mX\"\n",
        "\n",
        "      file_name = \"nin.keras\"\n",
        "      url = f\"https://drive.google.com/uc?id={nin}\"\n",
        "      gdown.download(url, file_name, quiet=False)\n",
        "      ninModel = load_model(file_name)\n",
        "\n",
        "      file_name = \"allconv.keras\"\n",
        "      url = f\"https://drive.google.com/uc?id={allconv}\"\n",
        "      gdown.download(url, file_name, quiet=False)\n",
        "      convModel = load_model(file_name)\n",
        "\n",
        "      file_name = \"vgg.keras\"\n",
        "      url = f\"https://drive.google.com/uc?id={vgg}\"\n",
        "      gdown.download(url, file_name, quiet=False)\n",
        "      vggModel = load_model(file_name)\n",
        "\n",
        "      return {\"conv\":convModel,\"nin\":ninModel, \"vgg\":vggModel}\n",
        "    else:\n",
        "      models = {\"conv\": createAllConvNetwork(), \"nin\":createNetworkInNetwork() , \"vgg\": createVGG()}\n",
        "      models = trainModels(models, data)\n",
        "      return models\n"
      ],
      "metadata": {
        "id": "MOrnMr8W5md_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=organiseData()\n",
        "models=createModels(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpeL7TUM6bQY",
        "outputId": "c59ce4b2-a1d4-431c-f60c-acce0e681d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DieuXWsbM4x_hVUOAY7Z2GhcR1Mk0dgN\n",
            "To: /content/trainLabels.csv\n",
            "100%|██████████| 589k/589k [00:00<00:00, 6.85MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1wOChHhwX6ANgLv2YCJpiYEtkPvFchy4G\n",
            "From (redirected): https://drive.google.com/uc?id=1wOChHhwX6ANgLv2YCJpiYEtkPvFchy4G&confirm=t&uuid=55e3f327-48df-4581-ab42-866c069d0457\n",
            "To: /content/train.7z\n",
            "100%|██████████| 110M/110M [00:00<00:00, 117MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted 'train.7z' into folder 'train/'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1OreWkCmQFr62Ekk6wvXtSeqXIy5154es\n",
            "From (redirected): https://drive.google.com/uc?id=1OreWkCmQFr62Ekk6wvXtSeqXIy5154es&confirm=t&uuid=a89480ac-c887-49f8-92ed-883e72e8233b\n",
            "To: /content/nin.keras\n",
            "100%|██████████| 33.0M/33.0M [00:00<00:00, 34.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNlJz_ktWGVM"
      },
      "source": [
        "# Differential Evolution\n",
        "\n",
        "Implementing differential evolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sci_pi_vectorized_one_pixel_de(\n",
        "    image,\n",
        "    model,\n",
        "    target_class,\n",
        "    bounds,\n",
        "    popsize=400,\n",
        "    maxiter=100,\n",
        "    batch_size=400,\n",
        "    crossover=0.7,\n",
        "    preprocess_fn=lambda x: x.astype(np.float32),\n",
        "    target=False,\n",
        "    verbose=False,\n",
        "  ):\n",
        "    # Change the target class based on whether this is a targeted attack or not\n",
        "    targeted_attack = target\n",
        "\n",
        "\n",
        "    # Define bounds for a flat vector of x,y,r,g,b values\n",
        "    # For more pixels, repeat this layout\n",
        "    bounds = [(0,32), (0,32), (0,256), (0,256), (0,256)]\n",
        "\n",
        "    # Population multiplier, in terms of the size of the perturbation vector x\n",
        "    popmul = max(1, popsize // len(bounds))\n",
        "\n",
        "    # Format the predict/callback functions for the differential evolution algorithm\n",
        "\n",
        "    def predict_fn(candidates):\n",
        "        # pop_candidates: (N, dims)\n",
        "        N = len(candidates[0])\n",
        "        copies = np.repeat(image[np.newaxis, ...], N, axis=0).astype(np.float32)\n",
        "        for i in range(N):\n",
        "            x = int(np.clip(round(candidates[0,i]), 0, image.shape[1]-1))\n",
        "            y = int(np.clip(round(candidates[1,i]), 0, image.shape[0]-1))\n",
        "            r, g, b = candidates[2,i], candidates[3,i], candidates[4,i]\n",
        "            copies[i, y, x] = [r, g, b]\n",
        "        # preprocess and predict in batches\n",
        "        preds = []\n",
        "        for start in range(0, N, batch_size):\n",
        "            end = start + batch_size\n",
        "            batch = preprocess_fn(copies[start:end])\n",
        "            p = model.predict(batch, verbose=0)\n",
        "            preds.append(p)\n",
        "        preds = np.vstack(preds)  # shape (N, num_classes)\n",
        "        # fitness: log prob of true_class (we minimize this)\n",
        "        if target:\n",
        "            for i in range(len(preds)):\n",
        "              preds[i][target_class] = 1 - preds[i][target_class]\n",
        "        fitness=np.log(preds[:,target_class] + 1e-12)\n",
        "\n",
        "        return fitness\n",
        "\n",
        "    STRATEGY=\"rand1bin\"\n",
        "    # Call Scipy's Implementation of Differential Evolution\n",
        "    attack_result = differential_evolution(\n",
        "        predict_fn,\n",
        "        bounds, maxiter=maxiter, popsize=popmul,vectorized=True, disp=verbose,strategy=STRATEGY, polish=True, recombination=crossover,\n",
        "        updating=\"deferred\",mutation=0.5,\n",
        "        #callback = callback_fn\n",
        "        )\n",
        "    return attack_result\n",
        "\n"
      ],
      "metadata": {
        "id": "Vm0090gmLbTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7yAvB5iioLe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def runAttack(targeted, target,model,img,  verbose=True):\n",
        "  label_keys = {0:\"dog\",1:\"frog\", 2:\"truck\", 3:\"deer\", 4:\"automobile\", 5:\"bird\", 6:\"horse\", 7:\"ship\", 8:\"cat\",9:\"airplane\" }\n",
        "\n",
        "  bounds = [(0,31),(0,31),(0,255),(0,255),(0,255)]\n",
        "  res = sci_pi_vectorized_one_pixel_de(\n",
        "      image=img,\n",
        "      model = model,\n",
        "      target_class=target,\n",
        "      target=targeted,\n",
        "      bounds=bounds,\n",
        "      popsize=400,\n",
        "      maxiter=100,\n",
        "      preprocess_fn=lambda x: x.astype(np.float32),\n",
        "  )\n",
        "  # Apply one-pixel attack using result from differential evolution\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEsKZyrCGs0U"
      },
      "outputs": [],
      "source": [
        "def successfulAttack(img, res,target_class, targeted, index=-1, model_name=\"vgg\"):\n",
        "\n",
        "    with open(\"targeted.txt\", \"w\") as f:\n",
        "      f.write(f\"Image Number,Predicted Class,True Class,Success,Confidence of Predicted,Confidence of Original Image Target Class,Model\\n\")\n",
        "\n",
        "    # Apply one-pixel attack using result from differential evolution\n",
        "    x,y= int(res.x[0]), int(res.x[1])\n",
        "    r, g, b = res.x[2], res.x[3], res.x[4]\n",
        "    adv_image = img.copy()\n",
        "    adv_image[y, x] = [r, g, b]\n",
        "    adv_pred = model.predict(adv_image[np.newaxis, ...])[0]\n",
        "    adv_class = np.argmax(adv_pred)\n",
        "\n",
        "    true_pred = model.predict(img[np.newaxis, ...])[0]\n",
        "    true_class_pred = true_pred[target_class]\n",
        "    adv_true_class = adv_pred[target_class]\n",
        "\n",
        "    if(targeted):\n",
        "        with open(\"targeted.txt\", \"a\") as f:\n",
        "            string = f\"{index},{adv_class},{target_class},{adv_class == target_class},{adv_pred[adv_class]},{true_class_pred},{model_name}\\n\"\n",
        "            print(\"OUTPUT:\")\n",
        "            print(string)\n",
        "            f.write(string)\n",
        "\n",
        "        return (adv_class ==   target_class , adv_pred, adv_true_class)\n",
        "    else:\n",
        "\n",
        "        with open(\"nontargeted.txt\", \"a\") as f:\n",
        "            f.write(f\"{index},{adv_class},{target_class},{adv_class != target_class},{adv_pred[adv_class]},{adv_true_class},{model_name}\\n\")\n",
        "        return (adv_class != target_class, adv_class, adv_true_class)\n",
        "\n",
        "def nonTargeted(model, data, num, model_name):\n",
        "  with open(\"nontargeted.txt\", \"w\") as f:\n",
        "    f.write(f\"Image Number,Predicted Class,True Class,Success,Confidence of Predicted,Confidence of True,Model\\n\")\n",
        "\n",
        "  out=[]\n",
        "  succCount=0\n",
        "  avgClass=0\n",
        "  avgTrueClass=0\n",
        "  count=0\n",
        "  for index in range(num):\n",
        "    print(count, \" Iteration\")\n",
        "    count+=1\n",
        "    print(index)\n",
        "    res = runAttack(target=int(data[\"y_test\"][index]), targeted=False, model=model, img=data[\"x_test\"][index], verbose=False)\n",
        "    resData=successfulAttack(data[\"x_test\"][index],res, int(data[\"y_test\"][index]), False, index, model_name)\n",
        "    if resData[0] :\n",
        "      succCount+=1\n",
        "    avgClass+=resData[1]\n",
        "    avgTrueClass+=resData[2]\n",
        "    print(resData)\n",
        "    print(\"Success:\", resData[0])\n",
        "    print(\"Predicted Class:\", resData[1])\n",
        "    print(\"Confidence of True Class:\", resData[2])\n",
        "    out.append(resData)\n",
        "\n",
        "  print(\"Success rate:\", succCount/num)\n",
        "  print(\"Class Confidence of highest confidence label:\", avgClass/num)\n",
        "  print(\"Average Confidence of correct label:\", avgTrueClass/num)\n",
        "  return out\n",
        "\n",
        "def targeted(model, data, num, model_name, offset=0):\n",
        "  out=[]\n",
        "  succCount=0\n",
        "  avgClass=0\n",
        "  avgTrueClass=0\n",
        "  count=0\n",
        "  targeted=True\n",
        "  for j in range(num):\n",
        "    index = j + offset\n",
        "    print(\"IMAGE NO:\", str(index))\n",
        "    for i in range(10):\n",
        "      if(i == int(data[\"y_test\"][index])):\n",
        "        continue\n",
        "      res = runAttack(target=i, targeted=targeted, model=model,img=data[\"x_test\"][index], verbose=True)\n",
        "      resData=successfulAttack(data[\"x_test\"][index],res, i, True, index, model_name)\n",
        "      print(i)\n",
        "      if resData[0] :\n",
        "        succCount+=1\n",
        "      avgClass+=resData[1]\n",
        "      avgTrueClass+=resData[2]\n",
        "      print(resData)\n",
        "      out.append(resData)\n",
        "\n",
        "  print(\"Success rate:\", succCount/num)\n",
        "  print(\"Class Confidence of highest confidence label:\", avgClass/num)\n",
        "  print(\"Average Confidence of correct label:\", avgTrueClass/num)\n",
        "  return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Simulation of targeted and non targeted attck for a specified  Model"
      ],
      "metadata": {
        "id": "tFBGg1XSWvPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Run Simulation\n",
        "model_name = \"vgg\"\n",
        "#conv for convolutional model, nin for network in network model, vgg for vgg model\n",
        "model = models[model_name]\n",
        "nonTargeted(model, data, 100, model_name)\n",
        "targeted(model,data,20, model_name)"
      ],
      "metadata": {
        "id": "dE5nuxrium82"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}